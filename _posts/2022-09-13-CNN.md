CNN (LeNet)


```python
from keras import backend
import tensorflow.keras as keras
from keras.models import Sequential
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers.core import Activation, Flatten, Dense
from keras.utils import np_utils
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import matplotlib.cm as cm
```


```python
# Data Processing #
(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()
X_train_std, X_test_std = X_train / 255.0, X_test / 255.0
X_train_std = X_train_std.astype('float32')
X_test_std = X_test_std.astype('float32')
y_train_onehot = tf.keras.utils.to_categorical(y_train, 10)
y_test_onehot = tf.keras.utils.to_categorical(y_test, 10)
```


```python
# image size : (28,28), gray scale #
class LeNet : 
    def build(input_shape, classes):
        model = Sequential()
        model.add(Conv2D(20, kernel_size = 5, padding="same", input_shape=input_shape))
        model.add(Activation("relu"))
        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))
        model.add(Conv2D(50, kernel_size = 5, padding="same"))
        model.add(Activation("relu"))
        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))
        model.add(Flatten())
        model.add(Dense(500))
        model.add(Activation("relu"))
        model.add(Dense(10))
        model.add(Activation("softmax"))
        return model
model = LeNet.build(input_shape = (28, 28, 1), classes = 10)
model.compile(loss = "categorical_crossentropy", optimizer=keras.optimizers.Adam(), metrics=["accuracy"])
history = model.fit(X_train_std, y_train_onehot, batch_size=256, epochs=10, verbose=1, validation_split=0.2)
```

    Epoch 1/10
    188/188 [==============================] - 69s 365ms/step - loss: 0.2512 - accuracy: 0.9251 - val_loss: 0.0779 - val_accuracy: 0.9774
    Epoch 2/10
    188/188 [==============================] - 89s 471ms/step - loss: 0.0608 - accuracy: 0.9808 - val_loss: 0.0514 - val_accuracy: 0.9831
    Epoch 3/10
    188/188 [==============================] - 98s 524ms/step - loss: 0.0434 - accuracy: 0.9860 - val_loss: 0.0407 - val_accuracy: 0.9887
    Epoch 4/10
    188/188 [==============================] - 86s 458ms/step - loss: 0.0311 - accuracy: 0.9902 - val_loss: 0.0414 - val_accuracy: 0.9873
    Epoch 5/10
    188/188 [==============================] - 75s 398ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 0.0366 - val_accuracy: 0.9893
    Epoch 6/10
    188/188 [==============================] - 78s 415ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.0344 - val_accuracy: 0.9898
    Epoch 7/10
    188/188 [==============================] - 72s 384ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0393 - val_accuracy: 0.9882
    Epoch 8/10
    188/188 [==============================] - 65s 344ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0331 - val_accuracy: 0.9906
    Epoch 9/10
    188/188 [==============================] - 70s 373ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.0388 - val_accuracy: 0.9894
    Epoch 10/10
    188/188 [==============================] - 63s 336ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0340 - val_accuracy: 0.9915
    


```python
model.summary()
```

    Model: "sequential_3"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     conv2d_6 (Conv2D)           (None, 28, 28, 20)        520       
                                                                     
     activation_12 (Activation)  (None, 28, 28, 20)        0         
                                                                     
     max_pooling2d_6 (MaxPooling  (None, 14, 14, 20)       0         
     2D)                                                             
                                                                     
     conv2d_7 (Conv2D)           (None, 14, 14, 50)        25050     
                                                                     
     activation_13 (Activation)  (None, 14, 14, 50)        0         
                                                                     
     max_pooling2d_7 (MaxPooling  (None, 7, 7, 50)         0         
     2D)                                                             
                                                                     
     flatten_3 (Flatten)         (None, 2450)              0         
                                                                     
     dense_6 (Dense)             (None, 500)               1225500   
                                                                     
     activation_14 (Activation)  (None, 500)               0         
                                                                     
     dense_7 (Dense)             (None, 10)                5010      
                                                                     
     activation_15 (Activation)  (None, 10)                0         
                                                                     
    =================================================================
    Total params: 1,256,080
    Trainable params: 1,256,080
    Non-trainable params: 0
    _________________________________________________________________
    


```python
prediction = model.predict(X_test_std)
idxShuffle = np.random.permutation(len(X_test_std))
fig = plt.figure(figsize = (10,30))
plt.subplots_adjust(hspace = 0.1, top = 0.97)
for i in range(10):
  index = idxShuffle[i]
  ax = fig.add_subplot(5,2,i+1)
  ax.set_title("pred : {} label : {}".format(np.argmax(prediction[i]), np.argmax(y_test_onehot[i])))
  ax.imshow(X_test_std[i], cmap = cm.gray)
plt.suptitle("Model Prediction")
plt.show()
```

    313/313 [==============================] - 5s 14ms/step
    


    
![png](output_5_1.png)
    


Kernel


```python
# Normalize filters (min/max) #
filters , bias = model.layers[0].get_weights()
f_min, f_max = filters.min(), filters.max()
filters_norm = (filters - f_min) / (f_max - f_min)
```


```python
filters_norm[:,:,:,:].shape
```




    (5, 5, 1, 20)




```python
# 첫번째 convolutional layer의 kernel #
n_filters = filters_norm.shape[-1]
n_channel = filters_norm.shape[-2]
fig = plt.figure(figsize = (10,20))
plt.subplots_adjust(top=0.95, hspace = 0.6, wspace = 0.1)
for i in range(n_filters):
    # get the filters
    f = filters_norm[:,:,:,i]
    for j in range(n_channel):
        # subplot for 6 filters and 1 channel 
        ax = fig.add_subplot(int(n_filters/2),n_channel*2, i+1)
        ax.imshow(f[:,:,j] ,cmap=cm.gray)
        ax.set_title('Filter {}'.format(i+1))
plt.suptitle('Kernel Visualization', fontsize = 20)
plt.show()
```


    
![png](output_9_0.png)
    


Feature Map


```python
# Sample image preprocessing #
from sklearn.datasets import load_sample_image
from skimage.transform import resize

china = load_sample_image('china.jpg')   
china_resize = resize(china, (28,28,3))
plt.imshow(china_resize)
china_test = np.expand_dims(np.expand_dims(china_resize[:,:,0], axis = -1), axis = 0)
china_test.shape
```




    (1, 28, 28, 1)




    
![png](output_11_1.png)
    



```python
# test를 위한 객체 생성 #
layer_output = [model.layers[i].output for i in range(len(model.layers))]
feature_map_model = tf.keras.models.Model(inputs = model.input, outputs = layer_output)
feature_map = feature_map_model.predict(china_test)
```

    1/1 [==============================] - 0s 145ms/step
    


```python
# Convolution layer (1,28,28,20) #
n_features = feature_map[0].shape[-1]
n_channels = feature_map[0].shape[0]
fig = plt.figure(figsize = (10,30))
for i in range(n_features):
  for j in range(n_channels):
    ax = fig.add_subplot(int(n_filters/2), n_channel*2, i+1)
    ax.imshow(feature_map[0][j,:,:,i], cmap = cm.gray)
    ax.set_title('Feature map {}'.format(i+1))
plt.suptitle('Convolution layer feature map', fontsize = 20)
plt.subplots_adjust(top = 0.95, hspace = 0.3)
plt.show()
```


    
![png](output_13_0.png)
    



```python
# Activation (1,28,28,20) #
n_features = feature_map[1].shape[-1]
n_channels = feature_map[1].shape[0]

fig = plt.figure(figsize = (10,30))
for i in range(n_features):
  for j in range(n_channels):
    ax = fig.add_subplot(int(n_filters/2), n_channel*2, i+1)
    ax.imshow(feature_map[1][j,:,:,i], cmap = cm.gray)
    plt.title('Feature map {}'.format(i+1))
plt.suptitle('Activation feature map',fontsize = 20)
plt.subplots_adjust(top = 0.95, hspace = 0.25)
plt.show()
```


    
![png](output_14_0.png)
    



```python
# Pooling layer (1,14,14,20) #
n_features = feature_map[2].shape[-1]
n_channels = feature_map[2].shape[0]
fig = plt.figure(figsize = (10,30))
for i in range(n_features):
  for j in range(n_channels):
    ax = fig.add_subplot(int(n_filters/2), n_channel*2, i+1)
    ax.imshow(feature_map[2][j,:,:,i], cmap = cm.gray)
    plt.title('Feature map {}'.format(i+1))
plt.suptitle('Pooling layer feature map', fontsize = 20)
plt.subplots_adjust(top = 0.95, hspace = 0.25)
plt.show()
```


    
![png](output_15_0.png)
    


Feature Extraction Process


```python
# Image 의 변화과정 #
feature_4dim = [feature_map[i] for i in range(len(feature_map)) if feature_map[i].ndim == 4]
fig = plt.figure(figsize = (10,30))
plt.suptitle('Feature extraction process',ha = 'center')
plt.subplots_adjust(top = 0.95, hspace = 0.3)

ax1 = fig.add_subplot(len(feature_4dim)+1, 1, 1)
ax1.imshow(china_test[0,:,:,0], cmap = cm.gray)
ax1.set_title('Original image')

for i in range(len(feature_4dim)):
  ax2 = fig.add_subplot(len(feature_4dim)+1, 1, i+2)
  ax2.imshow(feature_map[i][0,:,:,0], cmap = cm.gray)
  ax2.set_title('Feature map of layer {} ({})'.format((i+1), model.layers[i].name))
plt.show()
```


    
![png](output_17_0.png)
    


CIFAR-10 Classification using CNN  


```python
def unpickle(filepath):
    import pickle
    with open(filepath, 'rb') as fo:
        dict = pickle.load(fo, encoding='latin1')
    return dict

data1 = unpickle('C:/Users/윤철환/Desktop/Louis/VS_practice2/data_batch_1')
data2 = unpickle('C:/Users/윤철환/Desktop/Louis/VS_practice2/data_batch_2')
data3 = unpickle('C:/Users/윤철환/Desktop/Louis/VS_practice2/data_batch_3')
data4 = unpickle('C:/Users/윤철환/Desktop/Louis/VS_practice2/data_batch_4')
data5 = unpickle('C:/Users/윤철환/Desktop/Louis/VS_practice2/data_batch_5')
data_test = unpickle('C:/Users/윤철환/Desktop/Louis/VS_practice2/test_batch')
batch = unpickle('C:/Users/윤철환/Desktop/Louis/VS_practice2/batches.meta')
```


```python
# RGB 순으로 array가 들어있기 때문에 데이터 변환 #
# (3,32,32) -> (32,32,3) #
#  0  1  2  ->   1  2 0  #
new_dict_list = [data1, data2, data3, data4, data5, data_test, batch]

X_train_test = np.zeros([5,10000,32,32,3])

for i in range(5):
  for j in range(len(new_dict_list[i]['data'])):
    X_train_test[i,j,:,:,:] = new_dict_list[i]['data'][j].reshape(3,32,32).transpose(1,2,0)

X_train = np.r_[X_train_test[0],X_train_test[1]]
for i in range(3):
  X_train = np.r_[X_train, X_train_test[i+2]]

X_test = np.zeros([len(data_test['data']),32,32,3])
for i in range(len(data_test['data'])):
  X_test[i] = data_test['data'][i].reshape(3,32,32).transpose(1,2,0)

X_test_std = X_test / 255.0
X_train_std = X_train / 255.0
```


```python
y_train = np.array([])
for i in range(5):
  y_train = np.r_[y_train,new_dict_list[i]['labels']]
y_test = np.array(data_test['labels']).reshape(-1,1)

y_train_onehot = tf.keras.utils.to_categorical(y_train, 10)
y_test_onehot = tf.keras.utils.to_categorical(y_test, 10)

label = {0:'airplane',
         1:'automobile',
         2:'bird',
         3:'cat',
         4:'deer',
         5:'dog',
         6:'frog',
         7:'horse',
         8:'ship',
         9:'truck'}

print(X_train_std.shape, X_test_std.shape, y_train_onehot.shape, y_test_onehot.shape)
```

    (50000, 32, 32, 3) (10000, 32, 32, 3) (50000, 10) (10000, 10)
    


```python
# X_train, X_test, y_train, y_test 확인
idxShuffle = np.random.permutation(len(X_train_std))
fig = plt.figure(figsize = (10,30))
plt.subplots_adjust(hspace = 0.1)
for i in range(10):
  index = idxShuffle[i]
  ax = fig.add_subplot(5,2,i+1)
  ax.imshow(X_train_std[index])
  ax.set_title("{} {}".format(label[np.argmax(y_train_onehot[index])],index))
plt.show()
```


    
![png](output_22_0.png)
    



```python
# image size : (32,32,3), RGB scale #

class LeNet : 
    def build(input_shape, classes):
        model = Sequential()
        model.add(Conv2D(20, kernel_size = 5, padding="same", input_shape=input_shape))
        model.add(Activation("relu"))
        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))
        model.add(Conv2D(50, kernel_size = 5, padding="same"))
        model.add(Activation("relu"))
        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))
        model.add(Flatten())
        model.add(Dense(500))
        model.add(Activation("relu"))
        model.add(Dense(10))
        model.add(Activation("softmax"))
        return model
model = LeNet.build(input_shape = (32, 32, 3), classes = 10)
model.compile(loss = "categorical_crossentropy", optimizer=keras.optimizers.Adam(), metrics=["accuracy"])
history = model.fit(X_train_std, y_train_onehot, batch_size=100, epochs=10, verbose=1)
```

    Epoch 1/10
    500/500 [==============================] - 194s 378ms/step - loss: 1.4508 - accuracy: 0.4780
    Epoch 2/10
    500/500 [==============================] - 178s 356ms/step - loss: 1.0642 - accuracy: 0.6266
    Epoch 3/10
    500/500 [==============================] - 191s 381ms/step - loss: 0.8976 - accuracy: 0.6867
    Epoch 4/10
    500/500 [==============================] - 183s 365ms/step - loss: 0.7788 - accuracy: 0.7278
    Epoch 5/10
    500/500 [==============================] - 179s 357ms/step - loss: 0.6679 - accuracy: 0.7667
    Epoch 6/10
    500/500 [==============================] - 176s 353ms/step - loss: 0.5584 - accuracy: 0.8061
    Epoch 7/10
    500/500 [==============================] - 178s 357ms/step - loss: 0.4567 - accuracy: 0.8420
    Epoch 8/10
    500/500 [==============================] - 194s 388ms/step - loss: 0.3527 - accuracy: 0.8805
    Epoch 9/10
    500/500 [==============================] - 198s 395ms/step - loss: 0.2634 - accuracy: 0.9099
    Epoch 10/10
    500/500 [==============================] - 177s 354ms/step - loss: 0.1902 - accuracy: 0.9362
    


```python
prediction_CIFAR = model.predict(X_test_std)
idxShuffle = np.random.permutation(len(X_test_std))
fig = plt.figure(figsize = (10,30))
plt.subplots_adjust(hspace = 0.3)
for i in range(10):
  index = idxShuffle[i]
  ax = fig.add_subplot(5,2,i+1)
  ax.set_title('pred : {}, label : {}'.format(label[np.argmax(prediction_CIFAR[i])], label[np.argmax(y_test_onehot[i])]))
  ax.imshow(X_test_std[i])
plt.show()
```

    313/313 [==============================] - 7s 21ms/step
    


    
![png](output_24_1.png)
    


Kernel and Feature Map in CIFAR-10 Model


```python
from sklearn.datasets import load_sample_image
from skimage.transform import resize

flower = load_sample_image('flower.jpg')   
flower_resize = resize(flower, (32,32,3))
plt.imshow(flower_resize)
flower_test = np.expand_dims(flower_resize, axis = 0)
flower_test.shape
```




    (1, 32, 32, 3)




    
![png](output_26_1.png)
    



```python
# Normalize filters (min/max) #
filters , bias = model.layers[0].get_weights()
f_min, f_max = filters.min(), filters.max()
filters_norm = (filters - f_min) / (f_max - f_min)
filters_norm.shape
```




    (5, 5, 3, 20)




```python
# 첫번째 convolutional layer의 kernel #

ax = fig.add_subplot(int(n_filters/2), n_channel*2, i+1)

n_filters = filters_norm.shape[-1]
n_channel = filters_norm.shape[-2]
fig = plt.figure(figsize = (15,40))
plt.subplots_adjust(top=0.96, hspace = 0.5, wspace = 0.1)
for i in range(n_filters):
    # get the filters
    f = filters_norm[:,:,:,i]
    for j in range(n_channel):
        # subplot for 20 filters and 3 channels   
        ax = fig.add_subplot(n_filters, n_channel,i+1)  
        ax.imshow(f[:,:,j], cmap = cm.gray)
        ax.set_title('Filter {}'.format(i+1))
plt.suptitle('Kernel Visualization', fontsize = 20)
plt.show()
```


    
![png](output_28_0.png)
    



```python
# test를 위한 객체 생성 #
layer_output = [model.layers[i].output for i in range(len(model.layers))]
feature_map_model = tf.keras.models.Model(inputs = model.input, outputs = layer_output)
feature_map = feature_map_model.predict(flower_test)
```

    1/1 [==============================] - 1s 773ms/step
    


```python
# Image 의 변화과정 #
feature_4dim = [feature_map[i] for i in range(len(feature_map)) if feature_map[i].ndim == 4]
fig = plt.figure(figsize = (10,30))
plt.suptitle('Feature extraction process',ha = 'center')
plt.subplots_adjust(top = 0.95, hspace = 0.2)

ax1 = fig.add_subplot(len(feature_4dim)+1, 1, 1)
ax1.imshow(flower_test[0])
ax1.set_title('Original image')

for i in range(len(feature_4dim)):
  ax2 = fig.add_subplot(len(feature_4dim)+1, 1, i+2)
  ax2.imshow(feature_map[i][0,:,:,0])
  ax2.set_title('Feature map of layer {} ({})'.format((i+1), model.layers[i].name))
plt.show()
```


    
![png](output_30_0.png)
    

